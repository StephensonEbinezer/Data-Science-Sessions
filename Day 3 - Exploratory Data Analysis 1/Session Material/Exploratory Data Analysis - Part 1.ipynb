{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name: House price Prediction\n",
    "\n",
    "This is basically a regression problem(Predicts the continuos variable) with lot of categorical and numerical features associated with it\n",
    "\n",
    "##### Dataset and dataset description are available at : https://github.com/StephensonEbinezer/Data-Science-Sessions/tree/master/Day%203%20-%20Exploratory%20Data%20Analysis%201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Life Cycle of the Data science Project:\n",
    "\n",
    "    1) Data Analysis\n",
    "    2) Feature Engineering\n",
    "    3) Feature Selection\n",
    "    4) Model Building\n",
    "    5) Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Today we are going to focus on the Data Analysis(EDA)\n",
    "#our main aim to understand the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import missingno as msno\n",
    "import statistics\n",
    "\n",
    "pd.pandas.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r'C:\\Users\\steph\\Documents\\GitHub\\Data-Science-Sessions\\Day 3 - Exploratory Data Analysis 1\\Housing_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of rows and columns in the dataset\n",
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the datatype in the features\n",
    "Data.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['SalePrice'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we already know, there are following features\n",
    "    1) Categorical (Datatype of object)\n",
    "    2) Numerical - Continous (Datatype of Int or float)\n",
    "    3) Numercial - Discrete (Datatype of Int or float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 81 columns and 1460 rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to check the numerical and categorical features in the dataset\n",
    "categorical_features = []\n",
    "numerical_features = []\n",
    "Discrete_features = []\n",
    "Temporal_features = []\n",
    "Continous_features = []\n",
    "\n",
    "#To Segregate Catergorical and numerical features\n",
    "for feature in Data:\n",
    "    if Data[feature].dtypes == \"O\":\n",
    "        categorical_features.append(feature)\n",
    "    else:\n",
    "        numerical_features.append(feature)\n",
    "        \n",
    "#To Segregate discrete and continuos from the numerical features\n",
    "for feature in numerical_features:\n",
    "    if ('Yr' in feature or 'Year' in feature):\n",
    "        Temporal_features.append(feature)\n",
    "    elif Data[feature].nunique()<25:\n",
    "        Discrete_features.append(feature)\n",
    "    else:\n",
    "        Continous_features.append(feature)\n",
    "            \n",
    "print(\"NUmber of Categorical features are:\",len(categorical_features))\n",
    "print(\"NUmber of Numerical features are:\",len(numerical_features))\n",
    "print(\"NUmber of Discrete features are:\",len(Discrete_features))\n",
    "print(\"NUmber of Temporal features are:\",len(Temporal_features))\n",
    "print(\"NUmber of Continuos features are:\",len(Continous_features))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Data Analysis we will be dealing with\n",
    "    1) Missing Values(Handling will be part of Feature engineering)\n",
    "    2) All the numerical values\n",
    "    3) Distribution of numerical values\n",
    "    4) Categorical values\n",
    "    5) Cardinality of categorical values\n",
    "    6) Outliers analysis (handling will be part of festure engineering)\n",
    "    7) Relationship between the independent and dependent features(Target and features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of features/columns with null values with percentages\n",
    "feature_null = []\n",
    "for columns in Data:\n",
    "    if Data[columns].isnull().sum()>1:\n",
    "        feature_null.append(columns)\n",
    "for feature in feature_null:\n",
    "    print('% -15s%s'%(feature, np.round((Data[feature].isnull().mean())*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numbers of columns having missing values\n",
    "print('Number of Missing columns:',len(feature_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since there are many numbers of missing columns, we are going to see the relationship between the missing and target to check the impact of the missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_null:\n",
    "    Data_null = Data.copy()\n",
    "    #Creating a new dataframe for null values with the value 1 if null and 0 if not null\n",
    "    Data_null[feature] = np.where(Data_null[feature].isnull(),1,0)\n",
    "    \n",
    "    #Plotting the impact of null values to the target column\n",
    "    Data_null.groupby(feature)['SalePrice'].median().plot.bar(color = ['Orange','Blue','Green'])\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, wherever there is null value, our target price has increased or decreased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Numerical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    As we know,\n",
    "        NUmber of Numerical features are: 38\n",
    "        NUmber of Discrete features are: 7\n",
    "        NUmber of Temporal features are: 4\n",
    "        NUmber of Continuos features are: 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Temporal features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal feautes are associated with year, Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Temporal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in Temporal_features:\n",
    "    print(feature,Data[feature].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between the feature and the target \n",
    "for feature in Temporal_features:\n",
    "    Data.groupby(feature)['SalePrice'].median().plot()\n",
    "    plt.xlabel(feature,)\n",
    "    plt.ylabel('Median Saleprice')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are all the observations/inferences from the Numerical - Temporal features?\n",
    "    1) ???\n",
    "    2) ???\n",
    "    3) ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Numerical - Discrete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out the relationship between the dependant and indepandant features\n",
    "for feature in Discrete_features:\n",
    "    Data.groupby(feature)['SalePrice'].median().plot(kind = 'bar')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Median Saleprice')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are all the observations/inferences from the Discrete features?\n",
    "    1) ???\n",
    "    2) ???\n",
    "    3) ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Numerical - Continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Continous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions of the continuos features for skewness\n",
    "for feature in Continous_features:\n",
    "    Data[feature].plot(kind = 'hist')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other way to check the relationship is scatter lot\n",
    "for feature in Continous_features:\n",
    "    plt.scatter(Data[feature],Data['SalePrice'])\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('SalePrice')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Co-efficients for the numerical variable with the target feature\n",
    "for feature in Continous_features:\n",
    "    if feature not in 'Id':\n",
    "        A = Data[feature].corr(Data['SalePrice'])\n",
    "        print('%-20s%s'%(feature,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for the inter correlations visualization\n",
    "Data_Corr = pd.DataFrame(Data,columns=(Continous_features))\n",
    "Data_Corr.drop('Id',axis=1,inplace=True)\n",
    "Data_Corr = Data_Corr.corr()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(Data_Corr,annot=True,cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are all the observations/inferences from the Continuous features?\n",
    "    1) ???\n",
    "    2) ???\n",
    "    3) ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "    1) We need to understand what outlier is and what are all the components which will define this outlier\n",
    "    2) This is applicable only for the numerical continuos features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are nothing but an extreme value that deviates from the other observations in the dataset, in other words **data points which are so much deviated from the other data points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Before going to outlier, we need to understand the below statistical concepts\n",
    "        1) Mean\n",
    "        2) Median\n",
    "    \n",
    "           Mean is the average of the datapoint\n",
    "           Standard Deviation is the amount of variation\n",
    "           Median is the midpoint of the dataset\n",
    "           Mode is the most frequent occured value in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1,2,3,4,5,7]\n",
    "\n",
    "mean = statistics.mean(A)\n",
    "median = statistics.median(A)\n",
    "#mode = statistics.mode(A)\n",
    "std = statistics.stdev(A)\n",
    "\n",
    "print(mean)\n",
    "print(median)\n",
    "#print(mode)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impacts of outliers in the dataset\n",
    "    1) outliers will impact the analysis very badly\n",
    "    2) This will affect the mean and std of the dataset\n",
    "\n",
    "\n",
    "#### Ways to find out the outliers in the dataset\n",
    "    1) Scatter plot will show us the outlier in the dataset\n",
    "    2) Using Z-Score\n",
    "    3) Box Plot - Most used way to detect the outliers\n",
    "    3) IQR(Inter Quartile Range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Score\n",
    "\n",
    "Z-Score defines 'How much is the data deviated from the median with respect to Standard ddeviation\n",
    "- Z -Score = (Observed value - mean) / Standard deviation\n",
    "    - Z = (X-$\\mu$)/$\\sigma$\n",
    "\n",
    "![Z-Score](img/Z-Score.jpg)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Calculate the Z-Score\n",
    "for i in A:\n",
    "    z = (i-mean)/std\n",
    "    print(\"Z=Score for the value\",i,z)\n",
    "\n",
    "#Built in function to calculate the Z Score    \n",
    "from scipy import stats\n",
    "np.abs(stats.zscore(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Things to notice on Z-Score\n",
    "    1) Z Score should not be more than absolute of 3 for the value in the dataset, If so then it is outlier   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inter Quartile range\n",
    "    1 Arrange the datapoints in the ascending order\n",
    "    2 Calculate the First Quartile(Q1)\n",
    "    3 Calculate the Third qaurtile(Q2)\n",
    "    4 Find the interquartile range\n",
    "    5 Find the lower bound(Q1*1.5)\n",
    "    6 Find the higher bound(Q3*1.5)\n",
    "    \n",
    "![Inter_Quartile_Range(IQR)](img/IQR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IQR Oulier detection\n",
    "Q1 = np.percentile(A,25)\n",
    "Q3 = np.percentile(A,75)\n",
    "IQR = Q3-Q1\n",
    "Lower_bound = Q1-(1.5*IQR)\n",
    "Higher_bound = Q3+(1.5*IQR)\n",
    "\n",
    "print(\"25% Quartile for the dataset is:\",Q1)\n",
    "print(\"75% Quartile for the dataset is:\",Q3)\n",
    "print(\"Inter Quartile Range for the dataset is:\",IQR)\n",
    "print(\"Lower Bound for the dataset is:\",Lower_bound)\n",
    "print(\"Higher Bound for the dataset is:\",Higher_bound)\n",
    "\n",
    "sns.boxplot(data=A,orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](file:///C:/Users/steph/Downloads/Z-Score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will see the outliers in our dataset\n",
    "for feature in Continous_features:\n",
    "    sns.boxplot(x = Data[feature])\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find out the outliers in the dataset\n",
    "def outlier_detection(feature):\n",
    "    outlier = []\n",
    "    Q1,Q3 = np.percentile(Data[feature],(25,75))\n",
    "    lower_bound = Q1-(1.5*(Q3-Q1))\n",
    "    upper_bound = Q3+(1.5*(Q3-Q1))\n",
    "    \n",
    "    for data in Data[feature]:\n",
    "        if (data < lower_bound) or (data > upper_bound):\n",
    "            outlier.append(data)\n",
    "    return outlier\n",
    "\n",
    "for feature in Continous_features:\n",
    "    percentage_outliers = np.round(((len(outlier_detection(feature)))/len(Data[feature]))*100,2)\n",
    "    length_outliers = len(outlier_detection(feature)) \n",
    "    \n",
    "    print(\"{} has {} outliers records with {}%\".format(feature,length_outliers,percentage_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Catergorical Values\n",
    "\n",
    "     As we already know, number of Categorical features are: 43\n",
    "     \n",
    "     1) Check the cardinality of the categorical features\n",
    "     2) Check the relationship between the categorical and target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our categorical features are\n",
    "categorical_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cardinality of the features\n",
    "for feature in categorical_features:\n",
    "    print(\"Number of features for {} is : {}\".format(feature,Data[feature].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of categories play important role in feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship betwween the Caterogical features and Target featureusing bar plot\n",
    "for feature in categorical_features:\n",
    "    Data.groupby(feature)['SalePrice'].median().plot.bar()\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('SalePrice')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relationship between the caterogirical and target with boxplots\n",
    "for feature in categorical_features:\n",
    "    sns.boxplot(x = Data[feature],y=Data['SalePrice'],orient='v')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the observations/inferences from the categorical features\n",
    "    1) ???\n",
    "    2) ???\n",
    "    3) ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Today's Session\n",
    "    What have we learnt in today's session?\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
